# Glosario Big data

Glosario

|Concepto|¿Quién lo creo?|¿Cuándo?|Para qué sirve|Referencias
|:---:   |:---:          |:---:   |:---:         |:---:
|hadoop|  el ingeniero de software Doug Cutting |2004| describe en un documento técnicas para manejar grandes volúmenes de datos, desgranándolos en problemas cada vez más pequeños para hacerlos abordables.|(https://openwebinars.net/blog/que-es-hadoop/)
|ApacheFlume|Apache software fundation||es un servicio distribuido, fiable, y altamente disponible para recopilar, agregar, y mover eficientemente grandes cantidades de datos.|(https://bigdatadummy.com/2017/02/07/apache-flume/)
|MapReduce |Yahoo|2008| es un modelo de programación para dar soporte a la computación paralela sobre grandes colecciones de datos en grupos de computadoras|(https://es.wikipedia.org/wiki/MapReduce)
|Base de Daatos Estructuradas|Edgar Frank Codd|década de los setenta|	Base de datos que se puede percibir como un conjunto de tablas y se puede manipular según el modelo relacional de los datos|(https://www.ibm.com/support/knowledgecenter/es/SSFGJ4_7.6.0/com.ibm.mbs.doc/configur/r_ctr_db_structures.html)
|MongoDB |Geir Magnusson y Dwight Merriman.|11/02/2009|MongoDBes una base de datos orientada a documentos. Esto quiere decir que en lugar de guardar los datos en registros, guarda los datos en documentos. Estos documentos son almacenados en BSON, que es una representación binaria de JSON.|(https://www.mongodb.com/es/what-is-mongodb)
|Docker|Solomon Hykes|23/07/2013|puede usar los contenedores como máquinas virtuales extremadamente livianas y modulares. Además, obtiene flexibilidad con estos contenedores: puede crearlos, implementarlos, copiarlos y moverlos de un entorno a otro, lo cual le permite optimizar sus aplicaciones para la nube.|(https://www.redhat.com/es/topics/containers/what-is-docker)
|apache spark|Universidad de Berkeley|2008 |es un sistema de computación que se basa en Hadoop Map Reduce y que, principalmente, permite dividir o paralelizar el trabajo , ya que normalmente se instala en un clúster de máquina|(https://openwebinars.net/blog/que-es-apache-spark/)
|DRY | Steve Smith | 2014 | El principio DRY se declara como "Todo conocimiento debe tener una representación autoritaria, inequívoca y única dentro de un sistema". El principio ha sido formulado por Andy Hunt y Dave Thomas en su libro The Pragmatic Programmer . Lo aplican de manera bastante amplia para incluir " esquemas de bases de datos , planes de prueba , el sistema de compilación , incluso documentación ". Cuando el principio DRY se aplica con éxito, una modificación de cualquier elemento individual de un sistema no requiere un cambio en otros elementos lógicamente no relacionados. Además, los elementos que están relacionados lógicamente cambian de manera predecible y uniforme y, por lo tanto, se mantienen sincronizados . Además de utilizar métodos y subrutinas en su código, Thomas y Hunt confían en generadores de código , sistemas de compilación automática y lenguajes de secuencias de comandos para observar el principio DRY a través de las capas.| (https://en.wikipedia.org/wiki/Don%27t_repeat_yourself)
|KISS|Kelly Johnson|1960| El principio KISS establece que la mayoría de sistemas funcionan mejor si se mantienen simples que si se hacen complejos; por ello, la simplicidad debe ser mantenida como un objetivo clave del diseño, y cualquier complejidad innecesaria debe ser evitada.| (https://es.wikipedia.org/wiki/Principio_KISS)

